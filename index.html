<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Mastering Engine</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Inter', sans-serif;
        }
        .gradient-bg {
            background: linear-gradient(135deg, #1a202c, #2d3748, #4a5568);
        }
        .glass-card {
            background: rgba(255, 255, 255, 0.05);
            backdrop-filter: blur(10px);
            border: 1px solid rgba(255, 255, 255, 0.1);
        }
        #instructions-container h2 {
            font-size: 1.5rem;
            font-weight: 700;
            margin-top: 1.75rem;
            margin-bottom: 0.75rem;
            border-bottom: 1px solid #4a5568;
            padding-bottom: 0.5rem;
        }
        #instructions-container h3 {
            font-size: 1.25rem;
            font-weight: 600;
            margin-top: 1.5rem;
            margin-bottom: 0.5rem;
            color: #a0aec0;
        }
        #instructions-container p {
            margin-bottom: 1rem;
            line-height: 1.6;
        }
        #instructions-container ul {
            list-style-type: none;
            padding-left: 0;
        }
        #instructions-container li {
            position: relative;
            padding-left: 1.5rem;
            margin-bottom: 0.5rem;
        }
        #instructions-container li::before {
            content: '•';
            position: absolute;
            left: 0;
            color: #6366f1; /* Indigo */
            font-weight: bold;
        }
        #player-controls button:disabled {
            background-color: #4a5568;
            cursor: not-allowed;
            opacity: 0.5;
        }
        .settings-summary-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 1rem;
        }
        .settings-card {
            background: rgba(0,0,0,0.2);
            padding: 1rem;
            border-radius: 0.5rem;
        }
        .settings-card h5 {
            font-weight: bold;
            color: #90cdf4;
            margin-bottom: 0.5rem;
        }
        .settings-card ul {
            padding-left: 1rem;
            list-style-type: none;
        }
        .settings-card li {
            margin-bottom: 0.25rem;
            font-size: 0.875rem;
        }
        ::-webkit-scrollbar {
            width: 8px;
        }
        ::-webkit-scrollbar-track {
            background: #2d3748;
        }
        ::-webkit-scrollbar-thumb {
            background: #4a5568;
            border-radius: 4px;
        }
        ::-webkit-scrollbar-thumb:hover {
            background: #718096;
        }
    </style>
</head>
<body class="gradient-bg text-gray-200 min-h-screen flex items-center justify-center p-4">

    <div class="w-full max-w-4xl mx-auto">
        <header class="text-center mb-8">
            <h1 class="text-4xl md:text-5xl font-bold text-white tracking-tight">Interactive AI Mastering Engine</h1>
            <p class="text-lg text-gray-400 mt-2">Analyze, get instructions, and preview your master in real-time.</p>
        </header>

        <main class="glass-card rounded-2xl shadow-2xl p-6 md:p-8">
            <div id="upload-section">
                <div class="flex items-center justify-center w-full">
                    <label for="audio-upload" class="flex flex-col items-center justify-center w-full h-64 border-2 border-dashed border-gray-500 rounded-lg cursor-pointer bg-gray-700/50 hover:bg-gray-700/80 transition-colors">
                        <div class="flex flex-col items-center justify-center pt-5 pb-6">
                            <svg class="w-10 h-10 mb-4 text-gray-400" aria-hidden="true" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 20 16">
                                <path stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M13 13h3a3 3 0 0 0 0-6h-.025A5.56 5.56 0 0 0 16 6.5 5.5 5.5 0 0 0 5.207 5.021C5.137 5.017 5.071 5 5 5a4 4 0 0 0 0 8h2.167M10 15V6m0 0L8 8m2-2 2 2"/>
                            </svg>
                            <p class="mb-2 text-sm text-gray-400"><span class="font-semibold">Click to upload</span> or drag and drop</p>
                            <p class="text-xs text-gray-500">WAV, MP3, or FLAC (Max. 250MB)</p>
                        </div>
                        <input id="audio-upload" type="file" class="hidden" accept="audio/wav, audio/mpeg, audio/flac, .wav, .mp3, .flac">
                    </label>
                </div>
                <div id="file-info" class="text-center mt-4 text-gray-300 hidden">
                    <p>File: <span id="file-name" class="font-semibold"></span></p>
                </div>
                 <button id="get-instructions-btn" class="w-full mt-6 bg-indigo-600 hover:bg-indigo-700 text-white font-bold py-3 px-4 rounded-lg transition-all duration-300 disabled:bg-gray-500 disabled:cursor-not-allowed" disabled>
                    Analyze and Master
                </button>
            </div>

            <div id="result-section" class="hidden">
                <div id="loading-spinner" class="text-center">
                     <svg class="animate-spin h-10 w-10 text-white mx-auto" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24">
                        <circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle>
                        <path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path>
                    </svg>
                    <p id="loading-text" class="mt-4 text-gray-400">Initializing...</p>
                </div>

                <div id="player-controls" class="hidden text-center p-4 border-b border-gray-700 mb-4">
                    <h3 class="text-xl font-bold mb-4">Preview & Export (24-bit WAV)</h3>
                    <div class="flex flex-wrap justify-center gap-4">
                        <button id="preview-original-btn" class="bg-gray-500 hover:bg-gray-600 text-white font-bold py-2 px-6 rounded-lg transition-colors">Preview Original</button>
                        <button id="preview-mastered-btn" class="bg-green-600 hover:bg-green-700 text-white font-bold py-2 px-6 rounded-lg transition-colors">Preview Mastered</button>
                        <button id="download-mastered-btn" class="bg-blue-600 hover:bg-blue-700 text-white font-bold py-2 px-6 rounded-lg transition-colors">Download Mastered</button>
                    </div>
                </div>

                <div id="instructions-container" class="prose prose-invert max-w-none">
                </div>

                <div id="donation-section" class="hidden text-center mt-8 pt-6 border-t border-gray-700">
                    <p class="text-gray-400 mb-2">If you enjoy this service, please consider donating.</p>
                    <a href="https://coff.ee/iceestudios" target="_blank" rel="noopener noreferrer" class="inline-block bg-yellow-500 hover:bg-yellow-600 text-gray-900 font-bold py-2 px-4 rounded-lg transition-colors">
                        Buy me a coffee! ☕
                    </a>
                </div>

                <button id="reset-btn" class="w-full mt-4 bg-gray-600 hover:bg-gray-700 text-white font-bold py-3 px-4 rounded-lg transition-all duration-300 hidden">
                    Start Over
                </button>
            </div>
        </main>
    </div>

    <script>
        const uploadSection = document.getElementById('upload-section');
        const resultSection = document.getElementById('result-section');
        const audioUpload = document.getElementById('audio-upload');
        const getInstructionsBtn = document.getElementById('get-instructions-btn');
        const fileInfo = document.getElementById('file-info');
        const fileNameEl = document.getElementById('file-name');
        const loadingSpinner = document.getElementById('loading-spinner');
        const loadingText = document.getElementById('loading-text');
        const instructionsContainer = document.getElementById('instructions-container');
        const resetBtn = document.getElementById('reset-btn');
        const playerControls = document.getElementById('player-controls');
        const previewOriginalBtn = document.getElementById('preview-original-btn');
        const previewMasteredBtn = document.getElementById('preview-mastered-btn');
        const downloadMasteredBtn = document.getElementById('download-mastered-btn');
        const donationSection = document.getElementById('donation-section');

        let uploadedFile = null;
        let audioBuffer = null;
        let masteringSettings = null;
        let audioContext = null;
        let currentSource = null;
        let lastPlayedType = null;
        let isPlaying = false;

        const analyzeAudio = (file) => {
            return new Promise((resolve, reject) => {
                const reader = new FileReader();
                reader.onload = async (e) => {
                    try {
                        const tempAudioContext = new (window.AudioContext || window.webkitAudioContext)();
                        const buffer = await tempAudioContext.decodeAudioData(e.target.result);
                        tempAudioContext.close();
                        audioBuffer = buffer;

                        const offlineContext = new (window.OfflineAudioContext || window.webkitOfflineAudioContext)(
                            buffer.numberOfChannels, buffer.length, buffer.sampleRate
                        );
                        const source = offlineContext.createBufferSource();
                        source.buffer = buffer;
                        const analyser = offlineContext.createAnalyser();
                        analyser.fftSize = 4096;
                        const scriptProcessor = offlineContext.createScriptProcessor(4096, 1, 1);
                        const freqData = new Uint8Array(analyser.frequencyBinCount);
                        let chunkCount = 0;
                        const avgFreqData = new Float32Array(analyser.frequencyBinCount).fill(0);
                        scriptProcessor.onaudioprocess = () => {
                            analyser.getByteFrequencyData(freqData);
                            for (let i = 0; i < analyser.frequencyBinCount; i++) {
                                avgFreqData[i] += freqData[i];
                            }
                            chunkCount++;
                        };
                        source.connect(analyser);
                        analyser.connect(scriptProcessor);
                        scriptProcessor.connect(offlineContext.destination);
                        source.start(0);

                        offlineContext.startRendering().then(() => {
                            if (chunkCount > 0) {
                                for (let i = 0; i < analyser.frequencyBinCount; i++) {
                                    avgFreqData[i] /= chunkCount;
                                }
                            }
                            const pcmData = buffer.getChannelData(0);
                            let peak = 0, sumOfSquares = 0;
                            for (let i = 0; i < pcmData.length; i++) {
                                const sample = Math.abs(pcmData[i]);
                                if (sample > peak) peak = sample;
                                sumOfSquares += pcmData[i] * pcmData[i];
                            }
                            const rms = Math.sqrt(sumOfSquares / pcmData.length);
                            
                            const peakDb = peak > 0 ? 20 * Math.log10(peak) : -144;
                            const rmsDb = rms > 0 ? 20 * Math.log10(rms) : -144;
                            const crestFactor = peakDb - rmsDb;

                            const sampleRate = offlineContext.sampleRate;
                            const findPeakInRange = (startFreq, endFreq) => {
                                let maxVal = -1, peakFreq = -1;
                                const startIndex = Math.round(startFreq / sampleRate * analyser.fftSize);
                                const endIndex = Math.round(endFreq / sampleRate * analyser.fftSize);
                                for (let i = startIndex; i <= endIndex; i++) {
                                    if (avgFreqData[i] > maxVal) {
                                        maxVal = avgFreqData[i];
                                        peakFreq = Math.round(i * sampleRate / analyser.fftSize);
                                    }
                                }
                                return peakFreq;
                            };
                            const muddyFreq = findPeakInRange(200, 500);
                            const harshFreq = findPeakInRange(3000, 6000);
                            let spectralProfile = "balanced";
                            const bands = { bass: 0, mids: 0, highs: 0 };
                            let counts = { bass: 0, mids: 0, highs: 0 };
                            for(let i=0; i<analyser.frequencyBinCount; i++) {
                                const freq = i * sampleRate / analyser.fftSize;
                                const value = avgFreqData[i];
                                if (freq <= 250) { bands.bass += value; counts.bass++; }
                                else if (freq <= 4000) { bands.mids += value; counts.mids++; }
                                else { bands.highs += value; counts.highs++; }
                            }
                            const avgBass = counts.bass > 0 ? bands.bass / counts.bass : 0;
                            const avgMids = counts.mids > 0 ? bands.mids / counts.mids : 0;
                            const avgHighs = counts.highs > 0 ? bands.highs / counts.highs : 0;
                            if(avgBass > avgMids * 1.5 && avgBass > avgHighs * 1.5) spectralProfile = "bass-heavy";
                            else if(avgHighs > avgMids * 1.5 && avgHighs > avgBass * 1.5) spectralProfile = "bright";
                            else if(avgMids > avgBass * 1.3 && avgMids > avgHighs * 1.3) spectralProfile = "mid-forward";
                            else if(avgMids < avgBass * 0.7 && avgMids < avgHighs * 0.7) spectralProfile = "scooped";
                            resolve({ crestFactor, spectralProfile, muddyFreq, harshFreq, peakDb, rmsDb });
                        }).catch(reject);
                    } catch (error) { reject(new Error("Could not decode audio file. It may be corrupt or an unsupported format.")); }
                };
                reader.onerror = reject;
                reader.readAsArrayBuffer(file);
            });
        };

        const parseSettingsFromMarkdown = (markdown) => {
            const jsonBlockRegex = /```json\s*([\s\S]*?)\s*```/;
            const match = markdown.match(jsonBlockRegex);
            if (match && match[1]) {
                try {
                    return JSON.parse(match[1]);
                } catch (e) {
                    console.error("Failed to parse JSON settings block:", e);
                    return null;
                }
            }
            return null;
        };
        
        const createSettingsSummaryHTML = (settings) => {
            let html = '<div class="bg-gray-800 p-4 rounded-lg my-4"><h4 class="font-bold text-lg text-indigo-400 mb-4">Applied Settings Summary</h4><div class="settings-summary-grid">';

            if (settings.correctiveEQ) {
                html += '<div class="settings-card"><h5>Corrective EQ</h5><ul>';
                settings.correctiveEQ.forEach(eq => {
                    html += `<li>Cut ${Math.abs(eq.gain).toFixed(1)}dB @ ${eq.frequency}Hz (Q: ${eq.q})</li>`;
                });
                html += '</ul></div>';
            }
            if (settings.compressor) {
                const comp = settings.compressor;
                html += '<div class="settings-card"><h5>Compressor</h5><ul>';
                html += `<li>Threshold: ${comp.threshold.toFixed(1)}dB</li>`;
                html += `<li>Ratio: ${comp.ratio.toFixed(1)}:1</li>`;
                html += `<li>Attack: ${comp.attack}ms</li>`;
                html += `<li>Release: ${comp.release}ms</li>`;
                if (isFinite(comp.knee)) {
                    html += `<li>Knee: ${comp.knee.toFixed(1)}dB</li>`;
                }
                html += '</ul></div>';
            }
            if (settings.tonalEQ) {
                html += '<div class="settings-card"><h5>Tonal EQ</h5><ul>';
                settings.tonalEQ.forEach(eq => {
                    const action = eq.gain > 0 ? 'Boost' : 'Cut';
                    html += `<li>${action} ${Math.abs(eq.gain).toFixed(1)}dB @ ${eq.frequency}Hz (${eq.type})</li>`;
                });
                html += '</ul></div>';
            }
            if (settings.limiter) {
                const lim = settings.limiter;
                html += '<div class="settings-card"><h5>Loudness Maximizer</h5><ul>';
                html += `<li>Makeup Gain: +${lim.makeupGain.toFixed(1)} dB</li>`;
                html += `<li>Ceiling: ${lim.threshold.toFixed(1)} dBFS</li>`;
                html += `<li>Attack: ${lim.attack.toFixed(1)}ms</li>`;
                html += `<li>Release: ${lim.release.toFixed(1)}ms</li>`;
                html += '</ul></div>';
            }

            html += '</div></div>';
            return html;
        };
        
        function applyMasteringChain(context, sourceNode, settings) {
            let lastNode = sourceNode;
            if (!settings) return lastNode;

            const now = context.currentTime;

            if (settings.correctiveEQ) {
                settings.correctiveEQ.forEach(eq => {
                    if (isFinite(eq.frequency) && isFinite(eq.q) && isFinite(eq.gain)) {
                        const filter = context.createBiquadFilter();
                        filter.type = 'peaking';
                        filter.frequency.setValueAtTime(eq.frequency, now);
                        filter.Q.setValueAtTime(eq.q, now);
                        filter.gain.setValueAtTime(eq.gain, now);
                        lastNode.connect(filter);
                        lastNode = filter;
                    }
                });
            }
            if (settings.compressor) {
                const comp = settings.compressor;
                const compressor = context.createDynamicsCompressor();
                if(isFinite(comp.threshold)) compressor.threshold.setValueAtTime(comp.threshold, now);
                if(isFinite(comp.ratio)) compressor.ratio.setValueAtTime(comp.ratio, now);
                if(isFinite(comp.attack)) compressor.attack.setValueAtTime(comp.attack / 1000, now);
                if(isFinite(comp.release)) compressor.release.setValueAtTime(comp.release / 1000, now);
                if(isFinite(comp.knee)) compressor.knee.setValueAtTime(comp.knee, now);
                lastNode.connect(compressor);
                lastNode = compressor;
            }
            if (settings.tonalEQ) {
                settings.tonalEQ.forEach(eq => {
                    if (isFinite(eq.frequency) && isFinite(eq.gain) && eq.type) {
                        const filter = context.createBiquadFilter();
                        filter.type = eq.type;
                        filter.frequency.setValueAtTime(eq.frequency, now);
                        if(isFinite(eq.q)) filter.Q.setValueAtTime(eq.q, now);
                        filter.gain.setValueAtTime(eq.gain, now);
                        lastNode.connect(filter);
                        lastNode = filter;
                    }
                });
            }
            if (settings.limiter) {
                const lim = settings.limiter;
                if (isFinite(lim.makeupGain) && lim.makeupGain > 0) {
                    const makeupGainNode = context.createGain();
                    makeupGainNode.gain.setValueAtTime(Math.pow(10, lim.makeupGain / 20), now);
                    lastNode.connect(makeupGainNode);
                    lastNode = makeupGainNode;
                }
                const limiterNode = context.createDynamicsCompressor();
                if(isFinite(lim.threshold)) limiterNode.threshold.setValueAtTime(lim.threshold, now);
                limiterNode.knee.setValueAtTime(0, now);
                limiterNode.ratio.setValueAtTime(20, now);
                if(isFinite(lim.attack)) limiterNode.attack.setValueAtTime(lim.attack / 1000, now);
                if(isFinite(lim.release)) limiterNode.release.setValueAtTime(lim.release / 1000, now);
                lastNode.connect(limiterNode);
                lastNode = limiterNode;
            }
            return lastNode;
        }


        const updatePlayButtonStates = () => {
            if (isPlaying) {
                if (lastPlayedType === 'original') {
                    previewOriginalBtn.textContent = 'Pause';
                    previewMasteredBtn.textContent = 'Preview Mastered';
                } else {
                    previewMasteredBtn.textContent = 'Pause';
                    previewOriginalBtn.textContent = 'Preview Original';
                }
            } else {
                previewOriginalBtn.textContent = 'Preview Original';
                previewMasteredBtn.textContent = 'Preview Mastered';
            }
        };

        const togglePlayback = (type) => {
            if (!audioBuffer) return;

            if (isPlaying && lastPlayedType === type) {
                if (audioContext && audioContext.state === 'running') {
                    audioContext.suspend();
                }
                isPlaying = false;
            } 
            else if (!isPlaying && audioContext && audioContext.state === 'suspended' && lastPlayedType === type) {
                audioContext.resume();
                isPlaying = true;
            } 
            else {
                if (audioContext && audioContext.state !== 'closed') {
                    audioContext.close();
                }
                audioContext = new (window.AudioContext || window.webkitAudioContext)({sampleRate: audioBuffer.sampleRate});
                
                if (audioContext.state === 'suspended') {
                    audioContext.resume();
                }
                
                const source = audioContext.createBufferSource();
                source.buffer = audioBuffer;
                currentSource = source;

                let lastNode = source;
                if (type === 'mastered' && masteringSettings) {
                    try {
                       lastNode = applyMasteringChain(audioContext, source, masteringSettings);
                    } catch (e) {
                        console.error("Error applying mastering chain, playing original. Error:", e);
                        lastNode = source;
                    }
                }
                lastNode.connect(audioContext.destination);
                source.start(0);
                isPlaying = true;
                lastPlayedType = type;
                source.onended = () => {
                    isPlaying = false;
                    lastPlayedType = null;
                    if (audioContext && audioContext.state !== 'closed') {
                        audioContext.close();
                    }
                    updatePlayButtonStates();
                };
            }
            updatePlayButtonStates();
        };

        const exportMasteredFile = async () => {
            if (!audioBuffer || !masteringSettings) return;
            downloadMasteredBtn.disabled = true;
            downloadMasteredBtn.textContent = 'Exporting...';
            try {
                const offlineCtx = new (window.OfflineAudioContext || window.webkitOfflineAudioContext)(audioBuffer.numberOfChannels, audioBuffer.length, audioBuffer.sampleRate);
                const source = offlineCtx.createBufferSource();
                source.buffer = audioBuffer;
                
                const finalNode = applyMasteringChain(offlineCtx, source, masteringSettings);
                finalNode.connect(offlineCtx.destination);
                
                source.start(0);

                const renderedBuffer = await offlineCtx.startRendering();
                const wavBlob = bufferToWave(renderedBuffer, 24); // Request 24-bit export
                const url = URL.createObjectURL(wavBlob);
                const a = document.createElement('a');
                a.style.display = 'none'; a.href = url; a.download = 'mastered-track-24bit.wav';
                document.body.appendChild(a); a.click();
                window.URL.revokeObjectURL(url); a.remove();
            } catch (e) {
                console.error("Export failed:", e);
                alert("Sorry, the export failed.");
            } finally {
                downloadMasteredBtn.disabled = false;
                downloadMasteredBtn.textContent = 'Download Mastered';
            }
        };

        function bufferToWave(audioBuffer, bitDepth = 24) {
            const numChannels = audioBuffer.numberOfChannels;
            const sampleRate = audioBuffer.sampleRate;
            const numFrames = audioBuffer.length;
            const bytesPerSample = bitDepth / 8;

            const headerSize = 44;
            const dataSize = numFrames * numChannels * bytesPerSample;
            const fileSize = headerSize + dataSize;
            
            const buffer = new ArrayBuffer(fileSize);
            const view = new DataView(buffer);

            let pos = 0;

            view.setUint8(pos++, 0x52); view.setUint8(pos++, 0x49); view.setUint8(pos++, 0x46); view.setUint8(pos++, 0x46);
            view.setUint32(pos, fileSize - 8, true); pos += 4;
            view.setUint8(pos++, 0x57); view.setUint8(pos++, 0x41); view.setUint8(pos++, 0x56); view.setUint8(pos++, 0x45);
            view.setUint8(pos++, 0x66); view.setUint8(pos++, 0x6D); view.setUint8(pos++, 0x74); view.setUint8(pos++, 0x20);
            view.setUint32(pos, 16, true); pos += 4;
            view.setUint16(pos, 1, true); pos += 2;
            view.setUint16(pos, numChannels, true); pos += 2;
            view.setUint32(pos, sampleRate, true); pos += 4;
            view.setUint32(pos, sampleRate * numChannels * bytesPerSample, true); pos += 4;
            view.setUint16(pos, numChannels * bytesPerSample, true); pos += 2;
            view.setUint16(pos, bitDepth, true); pos += 2;
            view.setUint8(pos++, 0x64); view.setUint8(pos++, 0x61); view.setUint8(pos++, 0x74); view.setUint8(pos++, 0x61);
            view.setUint32(pos, dataSize, true); pos += 4;

            const channels = [];
            for (let i = 0; i < numChannels; i++) {
                channels.push(audioBuffer.getChannelData(i));
            }

            const maxInt = 8388607; // 2^(24-1) - 1
            
            for (let i = 0; i < numFrames; i++) {
                for (let j = 0; j < numChannels; j++) {
                    const floatSample = channels[j][i];
                    const clampedSample = Math.max(-1.0, Math.min(1.0, floatSample));
                    let intSample = Math.round(clampedSample * maxInt);
                    view.setUint8(pos++, intSample & 0xff);
                    view.setUint8(pos++, (intSample >> 8) & 0xff);
                    view.setUint8(pos++, (intSample >> 16) & 0xff);
                }
            }

            return new Blob([view], { type: 'audio/wav' });
        }


        previewOriginalBtn.addEventListener('click', () => togglePlayback('original'));
        previewMasteredBtn.addEventListener('click', () => togglePlayback('mastered'));
        downloadMasteredBtn.addEventListener('click', exportMasteredFile);

        audioUpload.addEventListener('change', (event) => {
            const files = event.target.files;
            if (files.length > 0) {
                uploadedFile = files[0];
                fileNameEl.textContent = uploadedFile.name;
                fileInfo.classList.remove('hidden');
                getInstructionsBtn.disabled = false;
            }
        });

        getInstructionsBtn.addEventListener('click', async () => {
            if (!uploadedFile) return;
            uploadSection.classList.add('hidden');
            resultSection.classList.remove('hidden');
            loadingSpinner.classList.remove('hidden');
            instructionsContainer.innerHTML = '';
            playerControls.classList.add('hidden');
            resetBtn.classList.add('hidden');
            donationSection.classList.add('hidden');
            
            try {
                loadingText.textContent = 'Performing deep audio analysis...';
                const analysis = await analyzeAudio(uploadedFile);
                loadingText.textContent = 'Analysis complete. Generating your custom guide...';

                // UPDATED: The prompt now targets -15dBFS RMS.
                const prompt = `
You are a world-class audio mastering engineer AI. You have just completed a deep digital analysis of an audio track.

Here is the data:
- **Peak Level:** ${analysis.peakDb.toFixed(1)} dBFS
- **RMS Level (Loudness proxy):** ${analysis.rmsDb.toFixed(1)} dBFS
- **Crest Factor:** ${analysis.crestFactor.toFixed(1)} dB
- **Spectral Profile:** **${analysis.spectralProfile}**
- **Muddy Frequency:** **${analysis.muddyFreq} Hz**
- **Harsh Frequency:** **${analysis.harshFreq} Hz**

Your task is to provide a step-by-step mastering guide in Markdown. You must also provide a JSON object containing the specific parameters for the audio processing chain. The final stage of this chain MUST be a limiter to bring the track to a competitive loudness for streaming platforms.

**IMPORTANT: Do NOT mention the JSON object at all in the user-facing guide.** The guide should be friendly and explain the reasoning for the settings without referring to the technical data structure.

**Crucially, the settings you describe in the text guide (e.g., "a small boost at 3kHz") MUST EXACTLY MATCH the numerical values you provide in the JSON object. When describing the Tonal EQ, you MUST use the word 'boost' if the 'gain' value is positive, and 'cut' if the 'gain' value is negative.**

**Your entire response must contain a single JSON block. Do not provide any example JSON.**

**RULES FOR THE JSON YOU GENERATE:**
- The JSON must be strictly valid. Do not include comments or trailing commas.
- The JSON must have four top-level keys: "correctiveEQ", "compressor", "tonalEQ", and "limiter".
- **correctiveEQ**: An array of two objects.
  - The first object's "frequency" property must be exactly **${analysis.muddyFreq}**.
  - The second object's "frequency" property must be exactly **${analysis.harshFreq}**.
  - Both objects must have "q" (Number) and "gain" (Number, should be negative) properties.
- **compressor**: An object with "threshold", "ratio", "attack", "release", and "knee" properties (all Numbers). 
  - The primary goal for compression is to apply gentle 'glue', with a maximum of 3dB of gain reduction.
  - You **must** set the parameters so that the compressor applies **no more than 3dB of gain reduction**.
  - Set a gentle "ratio", between 1.5 and 2.5. The track's peak level is ${analysis.peakDb.toFixed(1)} dBFS. You should set the "threshold" relative to this peak to achieve the target gain reduction.
  - Base the "attack" and "release" on the Spectral Profile. For a "bass-heavy" profile, use a slower attack (30-50ms). For a "bright" or "mid-forward" profile, use a faster attack (10-25ms). Set the release to be 3-5 times the attack time.
- **tonalEQ**: An array of three objects, each with "frequency", "q", "gain", and "type" properties.
  - The first object should be a "lowshelf" with a "frequency" around 120.
  - The second object should be a "peaking" EQ with a "frequency" between 2000 and 5000.
  - The third object should be a "highshelf" with a "frequency" around 12000.
  - Base the "gain" values on the Spectral Profile. If the profile is "bright", add less high-shelf gain and more low-shelf. If "bass-heavy", do the opposite.
- **limiter**: An object with "threshold", "attack", "release", and "makeupGain" properties.
  - The target RMS level before limiting is **-15.0 dBFS**. The track's initial RMS level is **${analysis.rmsDb.toFixed(1)} dBFS**.
  - Calculate the required "makeupGain" to bring the RMS level to the target of -15.0 dBFS. The formula is: makeupGain = -15.0 - (${analysis.rmsDb.toFixed(1)}). The final perceived loudness will be higher than this RMS value due to the density added by the limiter.
  - The "threshold" (also known as the ceiling) must be set to **-1.0** dB to prevent digital clipping.
  - Set a fast "attack" (1-5ms) and a moderate "release" (e.g., 100-200ms).
- "attack" and "release" values must be in milliseconds.
`;
                const apiUrl = 'https://ai-mastering-proxy.onrender.com/api/master';
                const response = await fetch(apiUrl, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ prompt: prompt }) 
                });
                if (!response.ok) {
                    const errorData = await response.json();
                    throw new Error(`API Error: ${response.statusText} - ${JSON.stringify(errorData)}`);
                }
                
                const result = await response.json();
                let text = 'Error: Could not retrieve instructions.';
                if (result.candidates?.[0]?.content?.parts?.[0]?.text) {
                    text = result.candidates[0].content.parts[0].text;
                }
                
                masteringSettings = parseSettingsFromMarkdown(text);
                
                let html;
                const jsonMatch = text.match(/```json\s*([\s\S]*?)\s*```/);
                if (masteringSettings && jsonMatch) {
                    html = text.replace(jsonMatch[0], createSettingsSummaryHTML(masteringSettings));
                } else {
                    html = text.replace(/```json[\s\S]*?```/, '');
                }

                html = html
                    .replace(/^### (.*$)/gim, '<h3>$1</h3>')
                    .replace(/^## (.*$)/gim, '<h2>$1</h2>')
                    .replace(/\*\*(.*?)\*\*/g, '<strong>$1</strong>')
                    .replace(/^\s*-\s(.*$)/gim, '<ul><li>$1</li></ul>')
                    .replace(/<\/ul>\s*<ul>/g, '')
                    .replace(/(\r\n|\n){2,}/g, '<div class="h-6"></div>')
                    .replace(/\n/g, '<br/>')
                    .replace(/<br\/><(h[23]|ul|div)/g, '<$1')
                    .replace(/<\/(h[23]|ul)><br\/>/g, '</$1>')
                    .replace(/<\/li><br\/>/g, '</li>');
                instructionsContainer.innerHTML = html;

                if (masteringSettings) {
                    playerControls.classList.remove('hidden');
                }

            } catch (error) {
                console.error('Error during analysis or fetch:', error);
                instructionsContainer.innerHTML = `<div class="text-red-400 text-center">
                    <p><strong>Oops! Something went wrong.</strong></p>
                    <p>${error.message}</p>
                    <p>Please try again with a different file.</p>
                    </div>`;
            } finally {
                loadingSpinner.classList.add('hidden');
                loadingText.textContent = "Initializing...";
                resetBtn.classList.remove('hidden');
                donationSection.classList.remove('hidden');
            }
        });
        
        resetBtn.addEventListener('click', () => {
            if (currentSource) { try { currentSource.stop(); } catch(e) {} }
            if (audioContext && audioContext.state !== 'closed') {
                audioContext.close();
            }
            uploadSection.classList.remove('hidden');
            resultSection.classList.add('hidden');
            playerControls.classList.add('hidden');
            instructionsContainer.innerHTML = '';
            fileInfo.classList.add('hidden');
            fileNameEl.textContent = '';
            getInstructionsBtn.disabled = true;
            audioUpload.value = '';
            uploadedFile = null;
            audioBuffer = null;
            masteringSettings = null;
            isPlaying = false;
            lastPlayedType = null;
            updatePlayButtonStates();
        });
    </script>
</body>
</html>
